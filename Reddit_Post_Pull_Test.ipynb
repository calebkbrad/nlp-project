{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "collapsed": true,
        "id": "32ziXN1DNSwJ",
        "outputId": "9b8f4f35-69e4-4cea-d26b-d3bb5d1ac1a7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-22-f07c615ac36f>, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-f07c615ac36f>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    pip install asyncpraw\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "# pip install praw"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install asyncpraw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ePY8h1ffWcpi",
        "outputId": "45956a69-45db-4df9-cf18-67dc123b3293"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting asyncpraw\n",
            "  Downloading asyncpraw-7.8.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting aiofiles (from asyncpraw)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: aiohttp<4 in /usr/local/lib/python3.10/dist-packages (from asyncpraw) (3.10.10)\n",
            "Collecting aiosqlite<=0.17.0 (from asyncpraw)\n",
            "  Downloading aiosqlite-0.17.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting asyncprawcore<3,>=2.1 (from asyncpraw)\n",
            "  Downloading asyncprawcore-2.4.0-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: update_checker>=0.18 in /usr/local/lib/python3.10/dist-packages (from asyncpraw) (0.18.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (4.0.3)\n",
            "Requirement already satisfied: typing_extensions>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from aiosqlite<=0.17.0->asyncpraw) (4.12.2)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from update_checker>=0.18->asyncpraw) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update_checker>=0.18->asyncpraw) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update_checker>=0.18->asyncpraw) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update_checker>=0.18->asyncpraw) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update_checker>=0.18->asyncpraw) (2024.8.30)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4->asyncpraw) (0.2.0)\n",
            "Downloading asyncpraw-7.8.0-py3-none-any.whl (196 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiosqlite-0.17.0-py3-none-any.whl (15 kB)\n",
            "Downloading asyncprawcore-2.4.0-py3-none-any.whl (19 kB)\n",
            "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: aiosqlite, aiofiles, asyncprawcore, asyncpraw\n",
            "Successfully installed aiofiles-24.1.0 aiosqlite-0.17.0 asyncpraw-7.8.0 asyncprawcore-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import praw\n",
        "import asyncpraw"
      ],
      "metadata": {
        "id": "Q1J_P7kONkN2"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Async PRAW](https://asyncpraw.readthedocs.io/en/stable/code_overview/models/subreddit.html)\\\n",
        "Documentation for Async PRAW, which works better when coding in Google Colab"
      ],
      "metadata": {
        "id": "zE8TS0O3cmOu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Connection to Reddit using Client ID (might create a new one later, this was set up as a test, and can add you as developer)"
      ],
      "metadata": {
        "id": "m44CNjY6dI0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reddit = asyncpraw.Reddit(\n",
        "    client_id=\"dMSJl79LluRNKLQmQo_zCg\",\n",
        "    client_secret=\"u9kX-PES2jIa1VAI-xaD70ysC3VAmw\",\n",
        "    user_agent=\"praw_odu_test\",\n",
        ")"
      ],
      "metadata": {
        "id": "KYYDvOAyNxp2"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "List of subreddits that we had identified. Can always expand the list if we want to. \\\n",
        "Can pick and choose from this list:\\\n",
        "[**List of Political Subreddits**](https://www.reddit.com/r/redditlists/comments/josdr/list_of_political_subreddits/?captcha=1)"
      ],
      "metadata": {
        "id": "6lIuLin_dsvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subreddit_list = [\n",
        "    'progressive','twoxchromosomes','kamalaharris','neoliberal','esist',\n",
        "    'politics','news','worldnews','politicalhumor',\n",
        "    'republican','libertarian','dailywire'\n",
        "    ]"
      ],
      "metadata": {
        "id": "VeGBC6d-Zz9X"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Test of the PRAW codes that pulled the top post from the selected subreddits from the last week"
      ],
      "metadata": {
        "id": "id94rpXYefAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for sub in subreddit_list:\n",
        "  subreddit = await reddit.subreddit(sub, fetch=True)\n",
        "  async for submission in subreddit.top(time_filter=\"week\", limit=1):\n",
        "    if not submission.stickied:\n",
        "      print(submission.title)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GM69Jokfavy3",
        "outputId": "9ed3f61c-f525-4f16-9aea-2e9e0eea4540"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A Texas Woman Died After Waiting 40 Hours for Miscarriage Care\n",
            "A Texas Woman Died After Waiting 40 Hours for Miscarriage Care\n",
            "Put on my boots, jumped in my F-150, and drove to the polls here in Texas.  Brought my wife and kids too.   We understood the assignment. \n",
            "if only Democrats toned down their rhetoric üò¢\n",
            "I dont as for much, please lord make this happen: Elon Musk Could Have US Citizenship Revoked If He Lied on Immigration Forms\n",
            "Arnold Schwarzenegger Endorses Kamala Harris: 'Don't Recognize Our Country'\n",
            "Elon Musk ordered to attend $1 million voter lottery suit hearing in Philadelphia court\n",
            "Over 100 women commit mass suicide in Sudan's Al Jazirah\n",
            "How the hell is this a close race?\n",
            "BREAKING: The US Supreme Court just blocked non citizen voters in Virginia.\n",
            "Property tax is theft. Change my mind.  \n",
            "Facts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not sure how we were going to determine the sentiment of the posts, but one thing that I was thinking was to use a \"lexicon\" of positive and negative words as the bag of words vector for the model. Below is a page that I found when I was looking at some things for Assignment 2"
      ],
      "metadata": {
        "id": "CLI0Wr85fAm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pos_url = 'https://raw.githubusercontent.com/shekhargulati/sentiment-analysis-python/refs/heads/master/opinion-lexicon-English/positive-words.txt'\n",
        "neg_url = 'https://raw.githubusercontent.com/shekhargulati/sentiment-analysis-python/refs/heads/master/opinion-lexicon-English/negative-words.txt'\n",
        "positive_lexicon = pd.read_csv(pos_url, sep='\\t', header=None)\n",
        "negative_lexicon = pd.read_csv(neg_url, sep='\\t', header=None,encoding='latin-1')"
      ],
      "metadata": {
        "id": "eQAveb7-feYy"
      },
      "execution_count": 55,
      "outputs": []
    }
  ]
}